{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84379a7b-33a0-4a07-94e3-60263120fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/Users/dursamiii/.nvm/versions/node/v22.20.0/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5076d59e-d71c-40be-aab4-521f9985d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83bf74a1bebeca5e2dd585eb582dc906e4ab81ae\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"x_auth_token\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f5856-85ea-4b00-a555-af133de80d1c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7827c0d4-af8c-4050-aa55-e5df4941d0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"Hasil_Crawling.csv\"\n",
    "search_keyword = \"Tepuk Sakinah\"\n",
    "limit = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a8751-a44b-4efc-bcc4-889e55c0c81f",
   "metadata": {},
   "source": [
    "### Mulai Nyari Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591b58c5-3d52-473e-8fe6-8e8cb9e84ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !npx -y tweet-harvest@latest -o \"{filename}\" -s \"{search_keyword}\" --tab LATEST -l {limit} --token {token}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b1ec8-69ea-465e-aafa-458d1012453b",
   "metadata": {},
   "source": [
    "### Lihat Hasil Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfb35fd-8480-4664-8646-21f0a660696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str</th>\n",
       "      <th>image_url</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975873064484343928</td>\n",
       "      <td>Wed Oct 08 10:37:03 +0000 2025</td>\n",
       "      <td>46</td>\n",
       "      <td>udah tepuk sakinah https://t.co/504dDxPHQf</td>\n",
       "      <td>1975873064484343928</td>\n",
       "      <td>https://pbs.twimg.com/media/G2u2Eg0aMAAJpQu.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://x.com/undefined/status/197587306448434...</td>\n",
       "      <td>1863567571175546880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973923616015462554</td>\n",
       "      <td>Fri Oct 03 01:30:38 +0000 2025</td>\n",
       "      <td>77</td>\n",
       "      <td>YANG UDAH NIKAH NGAKAK YANG BELOM NIKAH MUAAAK...</td>\n",
       "      <td>1973923616015462554</td>\n",
       "      <td>https://pbs.twimg.com/ext_tw_video_thumb/19739...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>https://x.com/undefined/status/197392361601546...</td>\n",
       "      <td>1481089289035579392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975184138199322949</td>\n",
       "      <td>Mon Oct 06 12:59:30 +0000 2025</td>\n",
       "      <td>160</td>\n",
       "      <td>tepuk sakinah tepuk trauma https://t.co/ihwpWX...</td>\n",
       "      <td>1975184138199322949</td>\n",
       "      <td>https://pbs.twimg.com/ext_tw_video_thumb/19751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>https://x.com/undefined/status/197518413819932...</td>\n",
       "      <td>761653636145356801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975366930891719027</td>\n",
       "      <td>Tue Oct 07 01:05:51 +0000 2025</td>\n",
       "      <td>18</td>\n",
       "      <td>Cuma IQ di atas 80 yg bisa menangkap pesan mor...</td>\n",
       "      <td>1975366930891719027</td>\n",
       "      <td>https://pbs.twimg.com/ext_tw_video_thumb/19753...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>https://x.com/undefined/status/197536693089171...</td>\n",
       "      <td>963751550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1974081204363432337</td>\n",
       "      <td>Fri Oct 03 11:56:50 +0000 2025</td>\n",
       "      <td>763</td>\n",
       "      <td>Menag Optimistis Tepuk Sakinah Bisa Redam Perc...</td>\n",
       "      <td>1974081204363432337</td>\n",
       "      <td>https://pbs.twimg.com/media/G2VYK0wbgAEu2pm.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>843</td>\n",
       "      <td>529</td>\n",
       "      <td>172</td>\n",
       "      <td>https://x.com/undefined/status/197408120436343...</td>\n",
       "      <td>23343960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id_str                      created_at  favorite_count  \\\n",
       "0  1975873064484343928  Wed Oct 08 10:37:03 +0000 2025              46   \n",
       "1  1973923616015462554  Fri Oct 03 01:30:38 +0000 2025              77   \n",
       "2  1975184138199322949  Mon Oct 06 12:59:30 +0000 2025             160   \n",
       "3  1975366930891719027  Tue Oct 07 01:05:51 +0000 2025              18   \n",
       "4  1974081204363432337  Fri Oct 03 11:56:50 +0000 2025             763   \n",
       "\n",
       "                                           full_text               id_str  \\\n",
       "0         udah tepuk sakinah https://t.co/504dDxPHQf  1975873064484343928   \n",
       "1  YANG UDAH NIKAH NGAKAK YANG BELOM NIKAH MUAAAK...  1973923616015462554   \n",
       "2  tepuk sakinah tepuk trauma https://t.co/ihwpWX...  1975184138199322949   \n",
       "3  Cuma IQ di atas 80 yg bisa menangkap pesan mor...  1975366930891719027   \n",
       "4  Menag Optimistis Tepuk Sakinah Bisa Redam Perc...  1974081204363432337   \n",
       "\n",
       "                                           image_url in_reply_to_screen_name  \\\n",
       "0    https://pbs.twimg.com/media/G2u2Eg0aMAAJpQu.jpg                     NaN   \n",
       "1  https://pbs.twimg.com/ext_tw_video_thumb/19739...                     NaN   \n",
       "2  https://pbs.twimg.com/ext_tw_video_thumb/19751...                     NaN   \n",
       "3  https://pbs.twimg.com/ext_tw_video_thumb/19753...                     NaN   \n",
       "4    https://pbs.twimg.com/media/G2VYK0wbgAEu2pm.jpg                     NaN   \n",
       "\n",
       "  lang  location  quote_count  reply_count  retweet_count  \\\n",
       "0   in       NaN            0            0              5   \n",
       "1   in       NaN           55           10             33   \n",
       "2   in       NaN            2           97              9   \n",
       "3   in       NaN            7           12              7   \n",
       "4   in       NaN          843          529            172   \n",
       "\n",
       "                                           tweet_url          user_id_str  \\\n",
       "0  https://x.com/undefined/status/197587306448434...  1863567571175546880   \n",
       "1  https://x.com/undefined/status/197392361601546...  1481089289035579392   \n",
       "2  https://x.com/undefined/status/197518413819932...   761653636145356801   \n",
       "3  https://x.com/undefined/status/197536693089171...            963751550   \n",
       "4  https://x.com/undefined/status/197408120436343...             23343960   \n",
       "\n",
       "   username  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = f\"tweets-data/{filename}\"\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d2113-100b-48b8-b553-d0f4d262bcf8",
   "metadata": {},
   "source": [
    "## Mulai Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd650010-6906-4c7f-a1bd-9382d9757d82",
   "metadata": {},
   "source": [
    "### 1. Case Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034cdf1-b957-46d1-85f3-e5a262156820",
   "metadata": {},
   "source": [
    "teks dijadikan huruf kecil semua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bbfdd7-d51d-4cc6-b951-2169aa749fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>casefolded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udah tepuk sakinah https://t.co/504dDxPHQf</td>\n",
       "      <td>udah tepuk sakinah https://t.co/504ddxphqf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YANG UDAH NIKAH NGAKAK YANG BELOM NIKAH MUAAAK...</td>\n",
       "      <td>yang udah nikah ngakak yang belom nikah muaaak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tepuk sakinah tepuk trauma https://t.co/ihwpWX...</td>\n",
       "      <td>tepuk sakinah tepuk trauma https://t.co/ihwpwx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cuma IQ di atas 80 yg bisa menangkap pesan mor...</td>\n",
       "      <td>cuma iq di atas 80 yg bisa menangkap pesan mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menag Optimistis Tepuk Sakinah Bisa Redam Perc...</td>\n",
       "      <td>menag optimistis tepuk sakinah bisa redam perc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0         udah tepuk sakinah https://t.co/504dDxPHQf   \n",
       "1  YANG UDAH NIKAH NGAKAK YANG BELOM NIKAH MUAAAK...   \n",
       "2  tepuk sakinah tepuk trauma https://t.co/ihwpWX...   \n",
       "3  Cuma IQ di atas 80 yg bisa menangkap pesan mor...   \n",
       "4  Menag Optimistis Tepuk Sakinah Bisa Redam Perc...   \n",
       "\n",
       "                                          casefolded  \n",
       "0         udah tepuk sakinah https://t.co/504ddxphqf  \n",
       "1  yang udah nikah ngakak yang belom nikah muaaak...  \n",
       "2  tepuk sakinah tepuk trauma https://t.co/ihwpwx...  \n",
       "3  cuma iq di atas 80 yg bisa menangkap pesan mor...  \n",
       "4  menag optimistis tepuk sakinah bisa redam perc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['casefolded'] = df['full_text'].str.lower()\n",
    "df[['full_text','casefolded']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055bb69-fd7b-4866-a61c-79b73087c6cd",
   "metadata": {},
   "source": [
    "### 2. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69642d8-ba6f-4358-a42a-93e1a4382562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e155c9-c72f-4966-8392-f813ed0a068f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "id_words = set(stopwords.words('indonesian'))\n",
    "eng_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tambahin daftar kata ga baku yg disingkat singkat\n",
    "custom_stopwords = {\n",
    "    'yg', 'sy', 'sdh', 'udh', 'dgn', 'dg', 'aja', 'nih', 'sih', 'sihh', 'nihh', 'ajaa', 'eh', 'ehh', 'ehhh',\n",
    "    'dong', 'tp', 'gk', 'ga', 'nggak', 'knp', 'trs', 'aja', 'bgt', 'nya', 'rp', 'bgt', 'bgtt', 'bgttt', 'jgn',\n",
    "    'bgtttt', 'sii', 'si', 'sih', 'siii', 'sihh', 'sihhh', 'jg', 'aj', 'tp', 'tpi', 'tuu', 'tuuu', 'tuhh', 'jgnn',\n",
    "    'nya', 'nih', 'loh', 'kok', 'lah', 'deh', 'kan', 'ya', 'yaa', 'yaaa', 'kann', 'yh', 'yhh', 'yhhh', 'jg',\n",
    "    'tuh', 'si', 'pun', 'pd', 'blm', 'kl', 'klo', 'klu', 'utk', 'biar','mah', 'deh', 'dehh', 'dehhh'\n",
    "}\n",
    "\n",
    "# Gabungkan dua set stopword\n",
    "stop_words = id_words.union(eng_words)\n",
    "stop_words = stop_words.union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3244b2-9a64-4be2-9777-5370d3571883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Hapus mention (@user)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Hapus hashtag (#tag)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Hapus URL (http, https)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Hapus angka\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Hapus simbol sm tanda baca, kecuali spasi\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Hapus stopword\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Terapkan ke kolom\n",
    "df['filtered'] = df['casefolded'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c68b72-a220-40af-a62b-53c342c9bf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casefolded</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udah tepuk sakinah https://t.co/504ddxphqf</td>\n",
       "      <td>udah tepuk sakinah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yang udah nikah ngakak yang belom nikah muaaak...</td>\n",
       "      <td>udah nikah ngakak belom nikah muaaak udah cera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tepuk sakinah tepuk trauma https://t.co/ihwpwx...</td>\n",
       "      <td>tepuk sakinah tepuk trauma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cuma iq di atas 80 yg bisa menangkap pesan mor...</td>\n",
       "      <td>iq menangkap pesan moral lagu tepuk sakinah be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>menag optimistis tepuk sakinah bisa redam perc...</td>\n",
       "      <td>menag optimistis tepuk sakinah redam perceraia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tepuk sakinah ini maksudnya baik tapi...</td>\n",
       "      <td>tepuk sakinah maksudnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ald1! gatau kenapa tapi sender ngebayangin mem...</td>\n",
       "      <td>ald gatau sender ngebayangin member bikin tepu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>makasih tepuk sakinah udah menyatukan skynani</td>\n",
       "      <td>makasih tepuk sakinah udah menyatukan skynani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kalo ga pengen nikah tapi hafal tepuk sakinah...</td>\n",
       "      <td>kalo pengen nikah hafal tepuk sakinah gpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>akan ku hadapi tepuk sakinah asal kamu calonny...</td>\n",
       "      <td>ku hadapi tepuk sakinah calonnya xixixi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           casefolded  \\\n",
       "0          udah tepuk sakinah https://t.co/504ddxphqf   \n",
       "1   yang udah nikah ngakak yang belom nikah muaaak...   \n",
       "2   tepuk sakinah tepuk trauma https://t.co/ihwpwx...   \n",
       "3   cuma iq di atas 80 yg bisa menangkap pesan mor...   \n",
       "4   menag optimistis tepuk sakinah bisa redam perc...   \n",
       "..                                                ...   \n",
       "95          tepuk sakinah ini maksudnya baik tapi...    \n",
       "96  ald1! gatau kenapa tapi sender ngebayangin mem...   \n",
       "97      makasih tepuk sakinah udah menyatukan skynani   \n",
       "98   kalo ga pengen nikah tapi hafal tepuk sakinah...   \n",
       "99  akan ku hadapi tepuk sakinah asal kamu calonny...   \n",
       "\n",
       "                                             filtered  \n",
       "0                                  udah tepuk sakinah  \n",
       "1   udah nikah ngakak belom nikah muaaak udah cera...  \n",
       "2                          tepuk sakinah tepuk trauma  \n",
       "3   iq menangkap pesan moral lagu tepuk sakinah be...  \n",
       "4   menag optimistis tepuk sakinah redam perceraia...  \n",
       "..                                                ...  \n",
       "95                            tepuk sakinah maksudnya  \n",
       "96  ald gatau sender ngebayangin member bikin tepu...  \n",
       "97      makasih tepuk sakinah udah menyatukan skynani  \n",
       "98          kalo pengen nikah hafal tepuk sakinah gpp  \n",
       "99            ku hadapi tepuk sakinah calonnya xixixi  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat hasilnya\n",
    "df[['casefolded', 'filtered']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3018c19-9612-4023-afa3-0016161a9035",
   "metadata": {},
   "source": [
    "### 3. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fca7b1-6f0f-4314-8811-d4c3da2d5b40",
   "metadata": {},
   "source": [
    "ubah jadi kata dasar semua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e79cd8-c706-4774-90ab-b2a1cfab4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# stemming langsung per kalimat\n",
    "df['stemmed'] = df['filtered'].apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f23cdc-2bfa-4889-b4af-05f64cace776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tbh dont get ppl hating tepuk sakinahits clums...</td>\n",
       "      <td>tbh dont get ppl hating tepuk sakinahits clums...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pringses tuk tepuk sakinah sm abang shuaaa nie...</td>\n",
       "      <td>pringses tuk tepuk sakinah sm abang shuaaa nie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>cc kantor urusan agama tepuk sakinah direktora...</td>\n",
       "      <td>cc kantor urus agama tepuk sakinah direktorat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>kalo selingkuh timggal panggil pake tepuk saki...</td>\n",
       "      <td>kalo selingkuh timggal panggil pake tepuk saki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tweet au part red zone tepuk sakinah</td>\n",
       "      <td>tweet au part red zone tepuk sakinah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>rumah tangga tepuk sakinah pajak tepuk coretax...</td>\n",
       "      <td>rumah tangga tepuk sakinah pajak tepuk coretax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>sli sljj</td>\n",
       "      <td>sli sljj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>nikah karna hapal tepuk sakinah</td>\n",
       "      <td>nikah karna hapal tepuk sakinah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>untung pas nikah tepuk sakinah bayangin suamik...</td>\n",
       "      <td>untung pas nikah tepuk sakinah bayangin suami ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>ahhhh cerai suamikuu kemarin udah tepuk sakina...</td>\n",
       "      <td>ahhhh cerai suamikuu kemarin udah tepuk sakina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filtered  \\\n",
       "151  tbh dont get ppl hating tepuk sakinahits clums...   \n",
       "152  pringses tuk tepuk sakinah sm abang shuaaa nie...   \n",
       "153  cc kantor urusan agama tepuk sakinah direktora...   \n",
       "154  kalo selingkuh timggal panggil pake tepuk saki...   \n",
       "155               tweet au part red zone tepuk sakinah   \n",
       "156  rumah tangga tepuk sakinah pajak tepuk coretax...   \n",
       "157                                           sli sljj   \n",
       "158                    nikah karna hapal tepuk sakinah   \n",
       "159  untung pas nikah tepuk sakinah bayangin suamik...   \n",
       "160  ahhhh cerai suamikuu kemarin udah tepuk sakina...   \n",
       "\n",
       "                                               stemmed  \n",
       "151  tbh dont get ppl hating tepuk sakinahits clums...  \n",
       "152  pringses tuk tepuk sakinah sm abang shuaaa nie...  \n",
       "153  cc kantor urus agama tepuk sakinah direktorat ...  \n",
       "154  kalo selingkuh timggal panggil pake tepuk saki...  \n",
       "155               tweet au part red zone tepuk sakinah  \n",
       "156  rumah tangga tepuk sakinah pajak tepuk coretax...  \n",
       "157                                           sli sljj  \n",
       "158                    nikah karna hapal tepuk sakinah  \n",
       "159  untung pas nikah tepuk sakinah bayangin suami ...  \n",
       "160  ahhhh cerai suamikuu kemarin udah tepuk sakina...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat hasil\n",
    "df[['filtered', 'stemmed']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658d67b-2b5c-4add-a7d8-0343a6b9a428",
   "metadata": {},
   "source": [
    "### 4. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f41f3c5-38db-4240-9736-d96fe1d2e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4115f6b6-59e1-44fb-86a1-5d98da4508cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udah tepuk sakinah</td>\n",
       "      <td>[udah, tepuk, sakinah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udah nikah ngakak bom nikah muaaak udah cerai ...</td>\n",
       "      <td>[udah, nikah, ngakak, bom, nikah, muaaak, udah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tepuk sakinah tepuk trauma</td>\n",
       "      <td>[tepuk, sakinah, tepuk, trauma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iq tangkap pesan moral lagu tepuk sakinah pasa...</td>\n",
       "      <td>[iq, tangkap, pesan, moral, lagu, tepuk, sakin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>menag optimistis tepuk sakinah redam cerai baca</td>\n",
       "      <td>[menag, optimistis, tepuk, sakinah, redam, cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boomer balas dendam genjet cipta tepuk sakinah</td>\n",
       "      <td>[boomer, balas, dendam, genjet, cipta, tepuk, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rumah tangga mulus turun sabar maaf janji suci...</td>\n",
       "      <td>[rumah, tangga, mulus, turun, sabar, maaf, jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tepuk sakinah doesnt make stay</td>\n",
       "      <td>[tepuk, sakinah, doesnt, make, stay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one want tepuk sakinah</td>\n",
       "      <td>[one, want, tepuk, sakinah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selamat hengky meyden bahagia sakinah tepuk sa...</td>\n",
       "      <td>[selamat, hengky, meyden, bahagia, sakinah, te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             stemmed  \\\n",
       "0                                 udah tepuk sakinah   \n",
       "1  udah nikah ngakak bom nikah muaaak udah cerai ...   \n",
       "2                         tepuk sakinah tepuk trauma   \n",
       "3  iq tangkap pesan moral lagu tepuk sakinah pasa...   \n",
       "4    menag optimistis tepuk sakinah redam cerai baca   \n",
       "5     boomer balas dendam genjet cipta tepuk sakinah   \n",
       "6  rumah tangga mulus turun sabar maaf janji suci...   \n",
       "7                     tepuk sakinah doesnt make stay   \n",
       "8                             one want tepuk sakinah   \n",
       "9  selamat hengky meyden bahagia sakinah tepuk sa...   \n",
       "\n",
       "                                           tokenized  \n",
       "0                             [udah, tepuk, sakinah]  \n",
       "1  [udah, nikah, ngakak, bom, nikah, muaaak, udah...  \n",
       "2                    [tepuk, sakinah, tepuk, trauma]  \n",
       "3  [iq, tangkap, pesan, moral, lagu, tepuk, sakin...  \n",
       "4  [menag, optimistis, tepuk, sakinah, redam, cer...  \n",
       "5  [boomer, balas, dendam, genjet, cipta, tepuk, ...  \n",
       "6  [rumah, tangga, mulus, turun, sabar, maaf, jan...  \n",
       "7               [tepuk, sakinah, doesnt, make, stay]  \n",
       "8                        [one, want, tepuk, sakinah]  \n",
       "9  [selamat, hengky, meyden, bahagia, sakinah, te...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Misal df['stemmed'] udah ada hasil stemming-nya\n",
    "df['tokenized'] = df['stemmed'].apply(word_tokenize)\n",
    "\n",
    "# Cek hasilnya\n",
    "df[['stemmed', 'tokenized']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c67a9-8fff-4069-9c8b-fb3814b65637",
   "metadata": {},
   "source": [
    "### Export hasil preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f8ee3c-0b2d-404e-9354-4d7b4636e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ubah ke tipe datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], format='%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "# Ambil tanggal & jam\n",
    "df['tanggal'] = df['created_at'].dt.date\n",
    "df['jam'] = df['created_at'].dt.time\n",
    "\n",
    "# Ambil kolom yang penting aja\n",
    "df_export = df[['tanggal', 'jam', 'stemmed']]\n",
    "\n",
    "# Ganti nama kolom biar rapi\n",
    "df_export.columns = ['tanggal', 'jam', 'text']\n",
    "\n",
    "# Export ke CSV\n",
    "df_export.to_csv(\"hasil_preprocess_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
